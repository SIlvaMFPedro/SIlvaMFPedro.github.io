<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<meta name="viewport"    content="width=device-width, initial-scale=1.0">
	<meta name="description" content="Semi-Automatic Labelling for Atlascar using Adaptive Perception">
	<meta name="author"      content="Pedro Silva">
	
	<title>Semi-Automatic Labelling for Atlascar using Adaptive Perception > Architecture</title>

	<link rel="shortcut icon" href="assets/images/pawn_icon.png">
	
	<link rel="stylesheet" media="screen" href="//fonts.googleapis.com/css?family=Open+Sans:300,400,700">
	<link rel="stylesheet" href="assets/css/bootstrap.min.css">
	<link rel="stylesheet" href="assets/css/font-awesome.min.css">

	<!-- Custom styles for our template -->
	<link rel="stylesheet" href="assets/css/bootstrap-theme.css" media="screen" >
	<link rel="stylesheet" href="assets/css/main.css">

	<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
	<!--[if lt IE 9]>
	<script src="assets/js/html5shiv.js"></script>
	<script src="assets/js/respond.min.js"></script>
	<![endif]-->
</head>

<body>
	<!-- Fixed navbar -->
	<div class="navbar navbar-inverse navbar-fixed-top headroom" >
		<div class="container">
			<div class="navbar-header">
			</div>
			<div class="navbar-collapse collapse">
				<ul class="nav navbar-nav pull-right">
					<li><a href="index.html">Home</a></li> <!-- Client area -->
					<li class="dropdown"> <!-- Specification area -->
						<a href="#" class="dropdown-toggle" data-toggle="dropdown">Specifications<b class="caret"></b></a>
						<ul class="dropdown-menu">
							<li><a href="specifications-1.html">Features, system scenarios and use cases</a></li>
							<li><a href="specifications-2.html">Requirements and tests</a></li>
							<li><a href="specifications-3.html">Architecture</a></li>
							<li class="active"><a href="specifications-4.html">Datasets</a></li>
							<li class="active"><a href="deliverables.html">Deliverables</a></li>
						</ul>
                    </li>
                    <li class="dropdown"> <!-- Client area -->
						<a href="#" class="dropdown-toggle" data-toggle="dropdown">About<b class="caret"></b></a>
						<ul class="dropdown-menu">
							<li><a href="aboutAtlas.html">About the ATLAS</a></li>
                            <li><a href="aboutCarla.html">About the CARLA</a></li>
						</ul>
                    </li>
                    <li><a href="manual.html">Integration with CARLA</a></li> <!-- Client area -->
				</ul>
			</div><!--/.nav-collapse -->
		</div>
	</div> 
	<!-- /.navbar -->

	<header id="head" class="secondary"></header>

	<!-- container -->
	<div class="container">
		
		<ol class="breadcrumb">
			<li><a href="index.html">Home</a></li>
			<li class="active">Architecture</li>
		</ol>

		<div class="row">

			<!-- Article main content -->
			<article class="col-sm-8 maincontent">
				<header class="page-header">
					<h1 class="page-title">Architecture</h1>
				</header>

				<div class="header-inside" id="spec-3-1">
					<h3>Architecture</h3>
					<hr class="half-rule"/>
					<p>&emsp;It is displayed in this section the architecture of the ROS-CARLA Integration software for the ATLASCAR implementation. Our architecture can be divided into 4 sections: one section that describes the central framework that runs with ROS, another section used for user interaction which is the CARLA simulator, another section that portrays the handling of the data between the ROS and CARLA modules and another section that is responsible for the image data processing.</p>
					<p>&emsp;The first section consists in a ROS node known as "roscore" that is responsible for handling the processes from the another ROS nodes that are part of the ATLASCAR configuration(LAR ToolKit). </p>
					<p>&emsp;The second section consists in open-world simulator known as CARLA that provides user interaction with all the agent models present in that world and command accordingly.</p>
					<p>&emsp;The third section, is the actual meat of the pie, which consists in a bridge package that handles the data provided from ROS and CARLA. To handle this complex problem of handling what we have to assume, could be an enormous amount of data, we adopt a divide and conquer strategy, aproaching the issue with a micro-services solution. Although in order to reduce the complexity of the problem we adopted a client-server model in which a user communicates with the apllication using a set of commands from the client API.</p>
					<!-- This section briefly describes the planned overall architecture of our solution. Our architecture is divided into 3 layers: <b>(1) Distributed data sources</b> (Data Generation Layer); <b>(2) IoT Platform</b> (Business Layer) and <b>(3) Applications</b> (Presentation Layer).</p>
					<p>&emsp;The distributed data sources layer sends the data gathered from the city to the IoT Platform, that stores and analyses all the data received. The IoT Platform also has the modules "AAA" and "IoT City Monitors and Alarms", that connect to the Application Layer to provide the user a fully functional and robust system. The application layer presents all the features to the user in a friendly way, with three custom applications, targeted for different users. --></p>
					<br>
					<div class="arch-div"><div class="h-caption" style="border-style: solid; border-color: grey;"><img src="./assets/images/rosgraph_carla.png" alt="The architecture of our solution"><br><h6>Architecture diagram of ROS-CARLA Integration</h6></div></div>
					<br>
					<p>&emsp;Elements of this Architecture may change according to the deemed needs faced during the development process of this software</p>
					<!-- <p>&emsp;On the <b>“Distributed data sources"</b> layer, we have a set of sensors for each type of data (lighting, waste, temperature,...). These sensors will collect data from the environment and send to an aggregator. The aggregators will send the information to a gateway, which will be the point of contact with the broker in the “IoT Platform”.</p>
					<p>&emsp;On the <b>“IoT Platform”</b>, the broker will receive the data from all the aggregators. The broker already exists in Altice Labs, and goes by the name of SmartIoT. SmartIoT is a platform that collects the data from the Altice Labs sensors that will be used in our project. The "AAA" module, where AAA stands for "Authentication, Authorization and Accounting" will be responsible for authenticate registered users. The "IoT City Monitors & Alarms" module will allow the user to add alerts to the data streams, with optional actuators defined. If any threshold is crossed, this module will notify the user and act accordingly. The module "IoT City Data Persistence" will store all the data from the IoT Platform. In some cases, it is also possible for the “IoT City Web App” to send information for the sensors (actuators). On that case, the information is sent to the SmartIoT broker, and then is sent to the sensor (actuator).</p><br>
					<p>&emsp;On the <b>“Applications”</b> layer we have the web portal, the administrator portal and the mobile application. The web portal is the interface for the city manager to see the current state of the city. The web portal uses the AAA module to authenticate its users, and receives the data from the IoT City Data Persistence. It also can add, change or delete alarms, notes and chage the state of user reports. The Administrator portal has the capability of adding sensors, streams, users, groups of users, and to do other changes on the IoT City Data Persistence Module. The IoT City Mobile Application requires no authentication, and it communicates with the IoT City Data Persistence to gather the values from sensors and create user reports.</p>  -->
					
				</div>
				
				<div class="header-inside" id="spec-3-2">
					<h3>Software Components</h3>
					<hr class="half-rule"/>
					<p>On this section we give an insight into each and every one of the components, explaining its main function and the external interface.</p>
					 
					<div class="header-inside" id="spec-3-3">
						<br><h4><b>ROS</b></h4><br>
						<p>&emsp;The central framework of this project is based on ROS Melodic on Ubuntu 18.04LTS</p>
						<p>&emsp;The ROS(Robot Operating System), although not an operating system, operates as a robotics middleware. 
										ROS offers open-source services designed for developers that need hardware abstraction and low-level device control. 
										Architectures in ROS are centered in applications called rosnodes which communicate with each other creating a graph of message-passing processes.
						</p>
						<p>&emsp;With ROS it is possible to receive data packets and transform them in messages that contain data from the sensors. 
										It is possible to manipulate this data using ROS nodes and other tools.</p>
					</div>

					<div class="header-inside" id="spec-3-4">
						<br><h4><b>RVIZ</b></h4><br>
						<p>&emsp;RVIZ is the standard ROS tool for 3D visualization. The Rviz is one of the most important tools as it will be used to visualize data either directly in real-time
										by connecting a computer to the car or in rosbags. It will also serve as a debugging tool in which pointcloud values can be analyzed (ROS Wiki 2018b).</p>
						<p><img src="./assets/images/rviz_config.png"></p>
					</div>

					<div class="header-inside" id="spec-3-5">
						<br><h4><b>Rosbag</b></h4><br>
						<p>&emsp;A rosbag is a file in ROS which contains messages saved from past events. While connected directly to a device, or several devices, multiple topics can be subscribed at once to be recorded into a rosbag. </p>
						<p>&emsp;The advantage of rosbags is to replicate the working environment of the ATLASCAR 2 offline. Several rosbags were recorded throughout the process of development in this project, either of calibration or for detection, tracking and labeling purposes.</p>
						<p>&emsp;In ROS, the rosbag package contains a set of tools for recording from and playing back to ROS topics. It is intended to be high performance and avoid deserialization and reserialization
										of the messages. It also features command line tools for working with bags as well as code APIs to read/write and manipulate bags (ROS Wiki 2018a).</p>
					</div>

					<div class="header-inside" id="spec-3-6">
						<br><h4><b>Roslaunch</b></h4><br>
						<p>&emsp; The roslaunch files are used as a tool for easily launching multiple ROS nodes. A roslaunch
								file sets up a roscore (os ROS master), sets parameters on the Parameter Server, and can also
								execute other roslaunch files.</p>
						<p>&emsp;It includes options to automatically re-spawn processes that have already died. The
								roslaunch takes in one or more XML configuration files (with the .launch extension) that
								specify the parameters to set and nodes to launch.</p>
						<p>&emsp;For example, a rosbag can be given as parameter to the roslaunch which opens the Rviz
								with a previous defined configuration to visualize the data from that rosbag.</p>
						<p>&emsp;In this project, roslaunch files are used to set up calibration values before launching the
								Rviz and the nodes that process the data from the LIDARs and the camera. The transforma-
								tions between device frames are set up using roslaunch files and static transform publishers
								implemented by ROS.</p>
						<p>&emsp;The roslaunch files are also advantageous to set up the multiple drivers needed to bring
								up the several devices equipped in the ATLASCAR 2. Since the sensors are connected to
								a network switch, the parameters given in the driver’s roslaunch file are the IP addresses of
								each of the devices. The drivers will then receive packets from the sensors and remap them
								into the ROS format.</p>
					</div>

					<div class="header-inside" id="spec-3-7">
						<br><h4><b>Rqt_bag</b></h4>
						<p>&emsp;The rqt bag is a GUI to replay and display ROS bag files. In this program it is possible to
								show bag message contents, view image messages, plot message from selected topics, publish
								messages from selected topics and export messages to a new bag. The rqt bag is useful for
								the labelling process as it presents a timeline in which the user can select the time by clicking
								on it.</p>
						<p><img src="./assets/images/rqt_bag.png"></p>
					</div>

					<div class="header-inside" id="spec-3-8">	
						<br><h4><b>LAR ToolKit</b></h4><br>
						<p>&emsp;The LARTk is a software suite developed by members of LAR. The projects involved in the LARTk are based in the development of robotics solutions namely for the ATLAS project.</p>
						<p>&emsp; This toolkit is constituted by a set of packages: <a target="_blank" href="http://lars.mec.ua.pt/lartk4/">LARtk4Wiki</a></p>
					</div>
					<div class="header-inside" id="spec-3-9">
						<br><h5><b>atlascar_base</b></h5><br>
						<p>This module establishes communication with the atlascar control PLC, handling all main control communications.</p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/atlascar_base">atlascar_base</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/atlascar_base">atlascar_base</a></p>
					</div>
					<div class="header-inside" id="spec-3-10">
					<br><h5><b>augmented_perception</b></h5><br>
						<p>This module is used to establish semi-automatic detection, tracking and labelling of active targets with the atlascar</p>
						<p>This package was developed by Nuno Miguel Soares Silva(2018): <a target="_blank" href="https://github.com/nmssilva">GitHub</a></p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/augmented_perception">augmented_perception</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/augmented_perception">augmented_perception</a></p>
					</div>
					<div class="header-inside" id="spec-3-11">
						<br><h5><b>calibration_gui</b></h5><br>
						<p>This multi-sensor calibration package contains a GUI used to calibrate the several sensors present in the ATLASCAR2</p>
						<p>The package was initially developed for the ATLASCAR1, and it was further introduced into the ATLASCAR2 since the sensors were almost the same</p>
						<p>The calibration package features a graphical user interface in which several sensors can be selected to be calibrated. The available devices are the SICK LMS151 and SICK LD-MRS mounted in the ATLASCAR 2, PointGrey cameras, Microsoft Kinects, the SwissRanger
							SR4000 and the Velodyne VLP16 used in the ATLASCAR1.</p>
						<p>To calibrate, the user should roll a ball in front of the sensors in order to create a pointcloud of ball centers, and then align them. The user adds the sensors that will
							be calibrated and inserts the IP address of the sensor. One of the sensors will be defined as the reference sensor.</p>
						<p><img src="./assets/images/calibration_gui.png"></p>
						<p>Some configurations can be done in the Options menu. The ball diameter can be defined here as well as the number of calibration points and distance between points. 
							The calibration also has two acquisition types: automatic or user prompt.</p>
						<p>In the automatic mode, while the ball rolls in front of the sensors the calibration programs automatically detects the ball center and publishes it. 
							In the user prompt mode the user chooses when the ball should be captured.</p>
						<p>In the end a file with the transformation matrices with the relative position of the sensors relatively to the reference sensor will be written.</p>
						<p>This package was developed by Vieira da Silva(2016)</p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/calibration_gui">calibration_gui</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/calibration_gui">calibration_gui</a></p>
					</div>
					<div class="header-inside" id="spec-3-12">
						<br><h5><b>colormap</b></h5><br>
						<p>This package serves as a library that can provide the same kind of functionality as a matlab colormap for the atlascar</p>
						<p>This package was developed by Professor Miguel Oliveira(2016): <a target="_blank" href="https://github.com/miguelriemoliveira">GitHub</a></p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/colormap">colormap</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/colormap">colormap</a></p>
					</div>
					<div class="header-inside" id="spec-3-13">
						<br><h5><b>free_space_detection</b></h5><br>
						<p></p>
						<p></p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/free_space_detection">free_space_detection</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/free_space_detection">free_space_detection</a></p>
					</div>
					<div class="header-inside" id="spec-3-14">
						<br><h5><b>kfilter</b></h5><br>
						<p>This package introduces a kalman filter to the atlascar which is a set of mathematical equations that provides an efficient computational (recursive) solution of the least-squares method.</p>
						<p>This filter is a very powerfull in several aspects:</p>
						<p>&emsp;- it supports estimations of past, present, and even future states, and it can do so even when the precise nature of the modeled system is unknown.</p>
						<p>&emsp;- it supports optimized algorithms even in the presence of correlated process or measurement noise.</p>
						<p>The version of this kalman filter is in fact a Variable-Dimension Extended Kalman Filter (VDEKF).</p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/kfilter">kfilter</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/kfilter">kfilter</a></p>
					</div>
					<div class="header-inside" id="spec-3-15">
						<br><h5><b>laser</b></h5><br>
						<p></p>
						<p></p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/laser">laser</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/laser">laser</a></p>
					</div>
					<div class="header-inside" id="spec-3-16">
						<br><h5><b>lidar_segmentation</b></h5><br>
						<p>This node is intended to explore some 2D laser segmentation algorithms.</p>
						<p>The segmentation process, whose objective is grouping segments that belong to the same object, is analysed using several kinds of algorithms:</p>
						<p>&emsp;- Simple Clustering.</p>
						<p>&emsp;- Multivariable Segmentation.</p>
						<p>&emsp;- Adaptive Breakpoint Detector.</p>
						<p>&emsp;- Dietmayer Segmentation (Jump Distance).</p>
						<p>&emsp;- Adapted Dietmayer Segmentation (Santos Segmentation).</p>
						<p>&emsp;- Spacial Nearest Neighbour (Recursive Method).</p>
						<p>The laser data is created from a .txt file with the ground-truth data.</p>
						<p>The results of the Several Algorithms can be seen on a rviz plataform The segmentation results (segments' centers and boundaries) are published into .txt files.</p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/lidar_segmentation">lidar_segmentation</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/lidar_segmentation">lidar_segmentation</a></p>
					</div>
					<div class="header-inside" id="spec-3-17">
						<br><h5><b>image_labelling</b></h5><br>
						<p></p>
						<p></p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/image_labelling">image_labelling</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/image_labelling">image_labelling</a></p>
					</div>
					<div class="header-inside" id="spec-3-18">
					<br><h5><b>mtt</b></h5><br>
						<p>The Multi Target Tracking(MTT) library is a set of methods and strategies specially designed for the ATLASCAR project with the goal to send perception parameters about objects captured in the LIDARs.</p>
						<p>The MTT is capable of receiving LIDAR messages and break them in smaller groups. This process is called clustering. Clustering separates all objects found in a scan and returns their position. 
							The clustering of data is an important step in the development of this dissertation as it facilitates the detection and tracking of objects in space.</p>
						<p>The clustering algorithm of the MTT library is based on the Nearest Neighbor Clustering Algorithm (Luo, Habibi and Mohrenschildt 2016). It segments the received pointclouds using
								a predefined distance as threshold. Each set of points in the clusters are assumed as possible targets of interest.</p>
						<p>The MTT then associates the targets found to a linked list of objects where the full description of the objects are stored. This list is later used to create a motion model where
								the estimated position of the objects and its velocity is calculated.</p>
						<p>Some objects may be occluded during the sequence (for example when a car passes in front of another). The MTT estimates the position of the occluded objects by creating a
								motion model using their velocity allowing objects to be followed while they are out of the field of view but still in the surroundings.</p>
						<p>The MTT defines targets that keep information about the object and its velocity plus their position and obstacle lines.</p>
						<p>This package was developed by Soares De Almeida(2016).</p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/mtt">mtt</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/mtt">mtt</a></p>
					</div>
					<div class="header-inside" id="spec-3-19">
						<br><h5><b>navigation_msgs</b></h5><br>
						<p></p>
						<p></p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/navigation_msgs">navigation_msgs</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/navigation_msgs">navigation_msgs</a></p>
					</div>
					<div class="header-inside" id="spec-3-20">
						<br><h5><b>odometer</b></h5><br>
						<p>This package receives velocity information from the Atlascar wheel encoder and its associated Arduino pulse counter.</p>
						<p>This package establishes a Ethernet communication with the Arduino server, it receives the number of pulses per second, the number of revolutions per second, the velocity of the vehicle and finally the simple counter value.</p>
						<p>This module publishes a locally defined status message with the received information.</p>
						<p>This module receives data at a weired rate of 9hz.</p>
						<p>The module makes use of the ros::diagnostics to publish the status of the Ethernet connection.</p>
						<p>On some occasions the Arduino takes a few seconds to start sending data.</p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/odometer">odometer</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/odometer">odometer</a></p>
					</div>
					<div class="header-inside" id="spec-3-21">
						<br><h5><b>python_scripts</b></h5><br>
						<p></p>
						<p></p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/python_scripts">python_scripts</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/python_scripts">python_scripts</a></p>
					</div>
					<div class="header-inside" id="spec-3-22">
						<br><h5><b>rqt_bag</b></h5><br>
						<p></p>
						<p></p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/rqt_bag">rqt_bag</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/rqt_bag">rqt_bag</a></p>
					</div>
					<div class="header-inside" id="spec-3-23">
						<br><h5><b>tcp_client</b></h5><br>
						<p>This module provides an easy to use TCP/IP client library. The library takes the form of a class that implements sys/socket, netinet/in and arpa/inet functions for socket control.</p>
						<p>Only a client class was developed and it only supports IPv4 and not IPv6, though the expansion is easy to achieve.</p>
						<p>For the more experienced user, the usage of the additional asynchronous client is highly recommended.</p>
						<p>This library is based on the boost::asio library supporting either IPv4 and IPv6 connections.</p>
						<p>This library is also accepts names of typical services (ssh, http, etc...) instead of port numbers.</p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/tcp_client">tcp_client</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/tcp_client">tcp_client</a></p>
					</div>
					<div class="header-inside" id="spec-3-24">
						<br><h5><b>topic_priority</b></h5><br>
						<p>This package provides a topic priority management library for atlascar</p>
						<p>This library allows a module to receive multiple command messages with different origins and order them by priority and lifetime. A topic is kept while its lifetime does not expire. Of the still surviving topics the one with the highest priority is returned.</p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/topic_priority">topic_priority</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/topic_priority">topic_priority</a></p>
					</div>
					<div class="header-inside" id="spec-3-25">
						<br><h5><b>velodyne_master</b></h5><br>
						<p></p>
						<p></p>
						<p>GitHub: <a target="_blank" href="https://github.com/SIlvaMFPedro/velodyne_master">velodyne_master</a></p>
						<p>RosWiki: <a target="_blank" href="http://wiki.ros.org/velodyne_master">velodyne_master</a></p>
					</div>


				</div>

				
				
			</article>
			<!-- /Article -->
			
			<!-- Sidebar -->
			<aside class="col-sm-4 sidebar sidebar-right">

				<div id="sidebar" class="row widget affix">
					<div class="col-xs-12">
						<h4>Choose the topic you want to see</h4>
						<ul class="list-unstyled list-spaces">
							<li><a href="#spec-3-1">Architecture</a><br><span class="small text-muted">This section contains the schematics of the architecture of the project.</span></li>
							<li><a href="#spec-3-2">Software Components</a><br><span class="small text-muted">On this section we give an insight into each and<br>every one of the software components present in this project.<!--, explaining its<br>main function and the interface with the exterior.--></span></li>
							<li><a href="#spec-3-3">ROS</a><br><span class="small text-muted">In this section we will explain the details of the ROS tool<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-4">RVIZ</a><br><span class="small text-muted">In this section we will explain the details of the RVIZ tool<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-5">Rosbag</a><br><span class="small text-muted">In this section we will explain the details of the Rosbag tool<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-6">Roslaunch</a><br><span class="small text-muted">In this section we will explain the details of the Roslaunch tool<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-7">Rqt_bag</a><br><span class="small text-muted">In this section we will explain the details of the Rqt_bag tool<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-8">LAR ToolKit</a><br><span class="small text-muted">In this section we will explain the details of the LAR ToolKit<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-9">atlascar_base</a><br><span class="small text-muted">In this section we will explain the details of the atlascar_base package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-10">augmented_perception</a><br><span class="small text-muted">In this section we will explain the details of the augmented_perception package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-11">calibration_gui</a><br><span class="small text-muted">In this section we will explain the details of the calibration_gui package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-12">colormap</a><br><span class="small text-muted">In this section we will explain the details of the colormap package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-13">free_space_detection</a><br><span class="small text-muted">In this section we will explain the details of the free_space_detection package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-14">kfilter</a><br><span class="small text-muted">In this section we will explain the details of the kfilter package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-15">laser</a><br><span class="small text-muted">In this section we will explain the details of the laser package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-16">lidar_segmentation</a><br><span class="small text-muted">In this section we will explain the details of the lidar_segmentation package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-17">image_labelling</a><br><span class="small text-muted">In this section we will explain the details of the image_labelling package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-18">mtt</a><br><span class="small text-muted">In this section we will explain the details of the mtt package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-19">navigation_msgs</a><br><span class="small text-muted">In this section we will explain the details of the navigation_msgs package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-20">odometer</a><br><span class="small text-muted">In this section we will explain the details of the odometer package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-21">python_scripts</a><br><span class="small text-muted">In this section we will explain the details of the python_scripts package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-22">rqt_bag</a><br><span class="small text-muted">In this section we will explain the details of the rqt_bag package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-23">tcp_client</a><br><span class="small text-muted">In this section we will explain the details of the tcp_client package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-24">topic_priority</a><br><span class="small text-muted">In this section we will explain the details of the topic_priority package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
							<li><a href="#spec-3-25">velodyne_master</a><br><span class="small text-muted">In this section we will explain the details of the velodyne_master package<!-- On this section we explain the deployment of our system,<br>with a diagram for better understanding of the reader. --></span></li>
						</ul>
					</div>
				</div>

			</aside>
			<!-- /Sidebar -->

		</div>
	</div>	<!-- /container -->
	

	<footer id="footer" class="top-space">

		<div class="footer2">
			<div class="container">
				<div class="row">
					
					<div class="col-md-6 widget">
						<div class="widget-body">
							<p class="simplenav">Master's Thesis - Computer and Telematics Engineering</p>
						</div>
					</div>

					<div class="col-md-6 widget">
						<div class="widget-body">
							<p class="text-right">
								Copyright &copy; 2019, Master's Thesis(DETI/DEM). Designed by <a href="http://gettemplate.com/" rel="designer">gettemplate</a> 
							</p>
						</div>
					</div>

				</div> <!-- /row of widgets -->
			</div>
		</div>
	</footer>
		




	<!-- JavaScript libs are placed at the end of the document so the pages load faster -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/bootstrap.min.js"></script>
	<script src="assets/js/headroom.min.js"></script>
	<script src="assets/js/jQuery.headroom.min.js"></script>
	<script src="assets/js/template.js"></script>
</body>
</html>
